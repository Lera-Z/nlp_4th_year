{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# import xgboost as xgb\n",
    "from pymystem3 import Mystem\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from stop_words import get_stop_words\n",
    "stop_words_421 = get_stop_words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for_final_table = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание и результаты"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(а) метод, которым был получен набор данных  \n",
    "- из НКРЯ было выбрано 700 контекстов со словом \"кошка\" и 700 контекстов со словом \"молекула\", эти слова заменены на XXX.  \n",
    "(б) Данные были скачаны из НКРЯ в формате xml, затем обработаны в Python  \n",
    "(в) предобработка: сначала были убраны  пометки в квадратных скобках об источнике текста, которые остались из НИКРЯ. Затем тексты были лемматизированы с помощью MyStem. Кроме того, были убраны стоп-слова.  \n",
    "(г) таблица с результатами по 7 моделям (gb = XGBoost, rf = RandomForest, ada = AdaBoost):  \n",
    "\n",
    "w2v_gb 0.632352941176  \n",
    "______________  \n",
    "w2v_rf 0.55525606469  \n",
    "______________  \n",
    "w2v_ada 0.642685851319  \n",
    "______________  \n",
    "tf_gb 0.855421686747  \n",
    "______________  \n",
    "tf_rf 0.886554621849  \n",
    "______________  \n",
    "tf_ada 0.847107438017  \n",
    "______________  \n",
    "pca_tf_gb 0.915766738661  \n",
    "______________  \n",
    "pca_tf_rf 0.781038374718  \n",
    "______________  \n",
    "pca_tf_ada 0.91914893617  \n",
    "______________  \n",
    "smallw2v_gb 0.675862068966  \n",
    "______________  \n",
    "smallw2v_rf 0.593350383632  \n",
    "______________  \n",
    "smallw2v_ada 0.662222222222  \n",
    "\n",
    "Лучшая комбинация - TF-IDF с классификатором AdaBoost после уменьшения размерности с помощью PCA. (pca_tf_ada 0.91914893617)  \n",
    "\n",
    "Обозначения: 1 - cat, 0 - molecule  \n",
    "\n",
    "(д) по 5 примеров ваших собственных на каждое значение (не из датасета) - результат применения к ним лучшего метода   \n",
    "\n",
    "молекула - это маленький частица вещество, определять его свойство и способный к самостоятельный существование.  \n",
    "prediction:[0]  \n",
    "\n",
    "вещество состоять из множество молекула  \n",
    "prediction:[0]  \n",
    "\n",
    "в школа мы проходить, как устраивать разный молекула  \n",
    "prediction:[0]  \n",
    "\n",
    "атом и молекула чрезвычайно маленький  \n",
    "prediction:[0]  \n",
    "\n",
    "к число важный класс биологический молекула относиться белок, углевод, липид и нуклеиновый кислота  \n",
    "prediction:[0]  \n",
    "____________________________________________________________  \n",
    "\n",
    "мой кошка прибегать ко я и начинать просить с она поиграть  \n",
    "prediction:[1]  \n",
    "\n",
    "за кошка нужно хорошо ухаживать  \n",
    "prediction:[1]  \n",
    "\n",
    "весь кошка хорошо видеть в темнота  \n",
    "prediction:[1]  \n",
    "\n",
    "я вчера подбирать на улица бездомный кошечка  \n",
    "prediction:[1]  \n",
    "\n",
    "кошка и собака не дружить  \n",
    "prediction:[1]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - cat, 0 - molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat = open('Cat.txt').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "molecule = open('Molecule.txt').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_clear = []\n",
    "molecule_clear = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for text in cat:\n",
    "    text_new = re.sub('\\[.*?\\] *', '', text)\n",
    "    text_new = text_new.replace('\\n', '')\n",
    "#     text_new = re.sub('(кош(е)?к[а-я]?)', 'word', text_new)\n",
    "    if any([x.isalpha() for x in text_new]):\n",
    "        cat_clear.append(text_new)\n",
    "\n",
    "for text in molecule:\n",
    "    text_new = re.sub('\\[.*?\\] *', '', text)\n",
    "    text_new = text_new.replace('\\n', '')\n",
    "#     text_new = re.sub('(молекул[а-я]*)', 'word', text_new)\n",
    "    if any([x.isalpha() for x in text_new]):\n",
    "        molecule_clear.append(text_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(cat_clear[1:], columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['class'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2 = pd.DataFrame(molecule_clear[1:], columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2['class'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.append(df_2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sents = []\n",
    "for sent in df.text:\n",
    "    arr = []\n",
    "    words = word_tokenize(sent)\n",
    "    for word in words:\n",
    "        lemma = m.lemmatize(word)[0]\n",
    "        if lemma == 'кошка' or lemma == 'молекула':\n",
    "            arr.append('XXX')\n",
    "        else:\n",
    "            if not '\\n' in lemma and lemma not in stop_words_421:\n",
    "                if any([x.isalpha() for x in lemma]):\n",
    "                    arr.append(lemma)\n",
    "    if arr:\n",
    "        sents.append(arr)\n",
    "    else:\n",
    "        print(\":{}:\".format(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(sents, size=300, window=5, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_vecs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for sent in sents:\n",
    "    vec = []\n",
    "    for word in sent:\n",
    "        try:\n",
    "            vec.append(model[word])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    try:\n",
    "        df_vecs.append(sum(vec)/len(vec))\n",
    "    except:\n",
    "        print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_vecs, df['class'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_gb = GradientBoostingClassifier(n_estimators=250, random_state=2)\n",
    "w2v_rf = RandomForestClassifier(random_state=2)\n",
    "w2v_ada = AdaBoostClassifier(random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.632352941176\n",
      "0.55525606469\n",
      "0.642685851319\n"
     ]
    }
   ],
   "source": [
    "for cl, name in zip([w2v_gb,w2v_rf, w2v_ada], ['w2v_gb','w2v_rf','w2v_ada']):\n",
    "    cl.fit(X_train, y_train)\n",
    "    y_pred = cl.predict(X_test)\n",
    "    score = f1_score(y_test, y_pred)\n",
    "    print(score)\n",
    "    for_final_table.append(name+' '+str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sents_join = [' '.join([x for x in sent if x != 'XXX' and x not in stop_words_421]) for sent in sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sents_join[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test_raw, y_train, y_test = train_test_split(sents_join, df['class'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_gb = GradientBoostingClassifier(n_estimators=250, random_state=2)\n",
    "tf_rf = RandomForestClassifier(random_state=2)\n",
    "tf_ada = AdaBoostClassifier(random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.855421686747\n",
      "0.886554621849\n",
      "0.847107438017\n"
     ]
    }
   ],
   "source": [
    "for cl, name in zip([tf_gb, tf_rf, tf_ada], ['tf_gb','tf_rf','tf_ada']):\n",
    "    cl.fit(X_train, y_train)\n",
    "    y_pred = cl.predict(X_test)\n",
    "    score = f1_score(y_test, y_pred)\n",
    "    print(score)\n",
    "    for_final_table.append(name+' '+str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "five_examples_cat = ['Моя кошка прибежала ко мне и начала просить с ней поиграть', 'За кошкой нужно хорошо ухаживать', 'Все кошки хорошо видят в темноте','Я вчера подобрал на улице бездомную кошечку', 'Кошки и собаки не дружат']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "five_examples_molecule = ['Молекула - это наименьшая частица вещества, определяющая его свойства и способная к самостоятельному существованию.','Вещества состоят из множества молекул', 'В школе мы проходили, как устроены разные молекулы', ' Атомы и молекулы чрезвычайно малы', 'К числу важных классов биологических молекул относятся белки, углеводы, липиды и нуклеиновые кислоты']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение размерности tf-idf с PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = TruncatedSVD(n_components=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_tr = pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_ts = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_gb = GradientBoostingClassifier(n_estimators=250, random_state=24)\n",
    "pca_rf = RandomForestClassifier(random_state=24)\n",
    "pca_ada = AdaBoostClassifier(random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.915766738661\n",
      "0.781038374718\n",
      "0.91914893617\n"
     ]
    }
   ],
   "source": [
    "for cl, name in zip([pca_gb,pca_rf, pca_ada], ['pca_tf_gb','pca_tf_rf','pca_tf_ada']):\n",
    "    cl.fit(X_tr, y_train)\n",
    "    y_pred = cl.predict(X_ts)\n",
    "    score = f1_score(y_test, y_pred)\n",
    "    print(score)\n",
    "    for_final_table.append(name+' '+str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "мой кошка прибегать ко я и начинать просить с она поиграть\n",
      "\n",
      "prediction:[1]\n",
      "за кошка нужно хорошо ухаживать\n",
      "\n",
      "prediction:[1]\n",
      "весь кошка хорошо видеть в темнота\n",
      "\n",
      "prediction:[1]\n",
      "я вчера подбирать на улица бездомный кошечка\n",
      "\n",
      "prediction:[1]\n",
      "кошка и собака не дружить\n",
      "\n",
      "prediction:[1]\n"
     ]
    }
   ],
   "source": [
    "# my = ['процесс', 'научный изучение', 'концентрация взрыв кристалл превращаться процесс', 'низкий температура упорядоченный процесс приводить к неожиданный научный вывод']\n",
    "for s in five_examples_cat:\n",
    "    s = ''.join(m.lemmatize(s))\n",
    "    vec = vectorizer.transform([s])\n",
    "    vec = pca.transform(vec)\n",
    "    print(s)\n",
    "    print(('prediction:{}').format(pca_ada.predict(vec)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение размерности w2v до 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_2 = gensim.models.Word2Vec(sents, size=150, window=2, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_vecs_2 = []\n",
    "for sent in sents:\n",
    "    vec = []\n",
    "    for word in sent:\n",
    "        try:\n",
    "            vec.append(model_2[word])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    \n",
    "    df_vecs_2.append(sum(vec)/len(vec))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_vecs_2, df['class'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smallw2v_gb = GradientBoostingClassifier(n_estimators=250, random_state=24)\n",
    "smallw2v_rf = RandomForestClassifier(random_state=24)\n",
    "smallw2v_ada = AdaBoostClassifier(random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.675862068966\n",
      "0.593350383632\n",
      "0.662222222222\n"
     ]
    }
   ],
   "source": [
    "for cl, name in zip([smallw2v_gb,smallw2v_rf, smallw2v_ada], ['smallw2v_gb','smallw2v_rf','smallw2v_ada']):\n",
    "    cl.fit(X_train, y_train)\n",
    "    y_pred = cl.predict(X_test)\n",
    "    score = f1_score(y_test, y_pred)\n",
    "    print(score)\n",
    "    for_final_table.append(name+' '+str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w2v_gb 0.632352941176\n",
      "______________\n",
      "w2v_rf 0.55525606469\n",
      "______________\n",
      "w2v_ada 0.642685851319\n",
      "______________\n",
      "tf_gb 0.855421686747\n",
      "______________\n",
      "tf_rf 0.886554621849\n",
      "______________\n",
      "tf_ada 0.847107438017\n",
      "______________\n",
      "pca_tf_gb 0.915766738661\n",
      "______________\n",
      "pca_tf_rf 0.781038374718\n",
      "______________\n",
      "pca_tf_ada 0.91914893617\n",
      "______________\n",
      "smallw2v_gb 0.675862068966\n",
      "______________\n",
      "smallw2v_rf 0.593350383632\n",
      "______________\n",
      "smallw2v_ada 0.662222222222\n",
      "______________\n"
     ]
    }
   ],
   "source": [
    "for item in for_final_table:\n",
    "    print(item)\n",
    "    print('______________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
