{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from pymystem3 import Mystem\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for_final_table = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(а) метод, которым был получен набор данных\n",
    "- из НКРЯ было выбрано 700 контекстов со словом \"кошка\" и 700 контекстов со словом \"молекула\", эти слова заменены на XXX.\n",
    "(б) Данные были скачаны из НКРЯ в формате xml, затем обработаны в Python\n",
    "(в) предобработка: сначала были убраны  пометки в квадратных скобках об источнике текста, которые остались из НИКРЯ. Затем тексты были лемматизированы с помощью MyStem\n",
    "(г) таблица с результатами по 7 моделям (gb = XGBoost, rf = RandomForest, ada = AdaBoost):\n",
    "\n",
    "w2v_gb 0.839662447257\n",
    "______________\n",
    "w2v_rf 0.731141199226\n",
    "______________\n",
    "w2v_ada 0.839400428266\n",
    "______________\n",
    "tf_gb 0.854251012146\n",
    "______________\n",
    "tf_rf 0.800821355236\n",
    "______________\n",
    "tf_ada 0.800821355236\n",
    "______________\n",
    "pca_tf_gb 0.839662447257\n",
    "______________\n",
    "pca_tf_rf 0.790890269151\n",
    "______________\n",
    "pca_tf_ada 0.839400428266\n",
    "______________\n",
    "smallw2v_gb 0.714606741573\n",
    "______________\n",
    "smallw2v_rf 0.635071090047\n",
    "______________\n",
    "smallw2v_ada 0.646924829157\n",
    "\n",
    "Лучшая комбинация - TF-IDF с классификатором XGBoost. \n",
    "\n",
    "(д) по 5 примеров ваших собственных на каждое значение (не из датасета) - результат применения к ним лучшего метода - комментарий к результатам (fp, fn ...)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - cat, 0 - molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat = open('Cat.txt').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "molecule = open('Molecule.txt').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_clear = []\n",
    "molecule_clear = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for text in cat:\n",
    "    text_new = re.sub('\\[.*?\\] *', '', text)\n",
    "#     text_new = re.sub('(кош(е)?к[а-я]?)', 'word', text_new)\n",
    "    cat_clear.append(text_new)\n",
    "\n",
    "for text in molecule:\n",
    "    text_new = re.sub('\\[.*?\\] *', '', text)\n",
    "#     text_new = re.sub('(молекул[а-я]*)', 'word', text_new)\n",
    "    molecule_clear.append(text_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(cat_clear[1:], columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['class'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_2 = pd.DataFrame(molecule_clear[1:], columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2['class'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.append(df_2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sents = []\n",
    "for sent in df.text:\n",
    "    arr = []\n",
    "    words = word_tokenize(sent)\n",
    "    for word in words:\n",
    "        lemma = m.lemmatize(word)[0]\n",
    "        if lemma == 'кошка' or lemma == 'молекула':\n",
    "            arr.append('XXX')\n",
    "        else:\n",
    "            arr.append(lemma)\n",
    "    sents.append(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(sents, size=300, window=2, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_vecs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for sent in sents:\n",
    "    vec = []\n",
    "    for word in sent:\n",
    "        try:\n",
    "            vec.append(model[word])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    \n",
    "    df_vecs.append(sum(vec)/len(vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_vecs, df['class'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w2v_gb = GradientBoostingClassifier(n_estimators=250, random_state=2)\n",
    "w2v_rf = RandomForestClassifier(random_state=2)\n",
    "w2v_ada = AdaBoostClassifier(random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.839662447257\n",
      "0.731141199226\n",
      "0.839400428266\n"
     ]
    }
   ],
   "source": [
    "for cl, name in zip([w2v_gb,w2v_rf, w2v_ada], ['w2v_gb','w2v_rf','w2v_ada']):\n",
    "    cl.fit(X_tr, y_train)\n",
    "    y_pred = cl.predict(X_ts)\n",
    "    score = f1_score(y_test, y_pred)\n",
    "    print(score)\n",
    "    for_final_table.append(name+' '+str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sents_join = [' '.join(sent) for sent in sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(sents_join, df['class'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_gb = GradientBoostingClassifier(n_estimators=250, random_state=2)\n",
    "tf_rf = RandomForestClassifier(random_state=2)\n",
    "tf_ada = AdaBoostClassifier(random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.854251012146\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.75      0.83       238\n",
      "          1       0.78      0.94      0.85       224\n",
      "\n",
      "avg / total       0.86      0.84      0.84       462\n",
      "\n",
      "0.800821355236\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.71      0.78       238\n",
      "          1       0.74      0.87      0.80       224\n",
      "\n",
      "avg / total       0.80      0.79      0.79       462\n",
      "\n",
      "0.800821355236\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.71      0.78       238\n",
      "          1       0.74      0.87      0.80       224\n",
      "\n",
      "avg / total       0.80      0.79      0.79       462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cl, name in zip([tf_gb, tf_rf, tf_ada], ['tf_gb','tf_rf','tf_ada']):\n",
    "    cl.fit(X_train, y_train)\n",
    "    y_pred = cl.predict(X_test)\n",
    "    score = f1_score(y_test, y_pred)\n",
    "    print(score)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    for_final_table.append(name+' '+str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tf_gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "five_examples_cat = ['Моя кошка прибежала ко мне и начала просить с ней поиграть', 'За кошкой нужно хорошо ухаживать', 'Все кошки хорошо видят в темноте','Я вчера подобрал на улице бездомную кошечку', 'Кошки и собаки не дружат']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "five_examples_molecule = ['Молекула - это наименьшая частица вещества, определяющая его свойства и способная к самостоятельному существованию.','Вещества состоят из множества молекул', 'В школе мы проходили, как устроены разные молекулы', ' Атомы и молекулы чрезвычайно малы', 'К числу важных классов биологических молекул относятся белки, углеводы, липиды и нуклеиновые кислоты']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Молекула - это наименьшая частица вещества, определяющая его свойства и способная к самостоятельному существованию.\n",
      "prediction:[1]\n",
      "Вещества состоят из множества молекул\n",
      "prediction:[1]\n",
      "В школе мы проходили, как устроены разные молекулы\n",
      "prediction:[1]\n",
      " Атомы и молекулы чрезвычайно малы\n",
      "prediction:[1]\n",
      "К числу важных классов биологических молекул относятся белки, углеводы, липиды и нуклеиновые кислоты\n",
      "prediction:[1]\n"
     ]
    }
   ],
   "source": [
    "for s in five_examples_molecule:\n",
    "    vec = vectorizer.transform([s])\n",
    "    print(s)\n",
    "    print(('prediction:{}').format(tf_gb.predict(vec)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение размерности tf-idf с PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = TruncatedSVD(n_components=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_tr = pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_ts = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_gb = GradientBoostingClassifier(n_estimators=250, random_state=24)\n",
    "pca_rf = RandomForestClassifier(random_state=24)\n",
    "pca_ada = AdaBoostClassifier(random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.839662447257\n",
      "0.790890269151\n",
      "0.839400428266\n"
     ]
    }
   ],
   "source": [
    "for cl, name in zip([pca_gb,pca_rf, pca_ada], ['pca_tf_gb','pca_tf_rf','pca_tf_ada']):\n",
    "    cl.fit(X_tr, y_train)\n",
    "    y_pred = cl.predict(X_ts)\n",
    "    score = f1_score(y_test, y_pred)\n",
    "    print(score)\n",
    "    for_final_table.append(name+' '+str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение размерности w2v до 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_2 = gensim.models.Word2Vec(sents, size=150, window=2, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_vecs_2 = []\n",
    "for sent in sents:\n",
    "    vec = []\n",
    "    for word in sent:\n",
    "        try:\n",
    "            vec.append(model_2[word])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    \n",
    "    df_vecs_2.append(sum(vec)/len(vec))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_vecs_2, df['class'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smallw2v_gb = GradientBoostingClassifier(n_estimators=250, random_state=24)\n",
    "smallw2v_rf = RandomForestClassifier(random_state=24)\n",
    "smallw2v_ada = AdaBoostClassifier(random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.714606741573\n",
      "0.635071090047\n",
      "0.646924829157\n"
     ]
    }
   ],
   "source": [
    "for cl, name in zip([smallw2v_gb,smallw2v_rf, smallw2v_ada], ['smallw2v_gb','smallw2v_rf','smallw2v_ada']):\n",
    "    cl.fit(X_train, y_train)\n",
    "    y_pred = cl.predict(X_test)\n",
    "    score = f1_score(y_test, y_pred)\n",
    "    print(score)\n",
    "    for_final_table.append(name+' '+str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w2v_gb 0.839662447257\n",
      "______________\n",
      "w2v_rf 0.731141199226\n",
      "______________\n",
      "w2v_ada 0.839400428266\n",
      "______________\n",
      "tf_gb 0.854251012146\n",
      "______________\n",
      "tf_rf 0.800821355236\n",
      "______________\n",
      "tf_ada 0.800821355236\n",
      "______________\n",
      "pca_tf_gb 0.839662447257\n",
      "______________\n",
      "pca_tf_rf 0.790890269151\n",
      "______________\n",
      "pca_tf_ada 0.839400428266\n",
      "______________\n",
      "smallw2v_gb 0.714606741573\n",
      "______________\n",
      "smallw2v_rf 0.635071090047\n",
      "______________\n",
      "smallw2v_ada 0.646924829157\n",
      "______________\n"
     ]
    }
   ],
   "source": [
    "for item in for_final_table:\n",
    "    print(item)\n",
    "    print('______________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
